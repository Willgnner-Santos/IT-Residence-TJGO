# CLASSIFICANDO-PERFIL-DE-CONCILIA√á√ÉO

Este reposit√≥rio organiza um pipeline para **classificar o perfil de concilia√ß√£o** (ex.: processos do CEJUSC), combinando:
- **pr√©-processamento** e gera√ß√£o de features (regex / atributos tabulares / features via LLM)
- **embeddings** (ex.: Gemini/SBERT) com checkpoint parcial
- **treinamento e avalia√ß√£o** com modelos cl√°ssicos (XGBoost / RandomForest / LightGBM / CatBoost)
- uma **vers√£o de teste em produ√ß√£o** (app + Docker) para servir o modelo

> ‚ö†Ô∏è **Importante (LGPD / dados sens√≠veis):** este reposit√≥rio foi estruturado para **n√£o versionar dados reais** (CSV/JSON), embeddings e artefatos pesados/derivados (PKL/NPY/checkpoints). A documenta√ß√£o abaixo deixa claro o que fica **local** vs o que vai para o **GitHub**.

---

## Estrutura do reposit√≥rio (vis√£o local)

Abaixo est√° uma vis√£o **do seu ambiente local**, com dados e artefatos.  
Ela serve como refer√™ncia para organiza√ß√£o (voc√™ pode inserir um print nessa se√ß√£o).

üìå **Print da estrutura (coloque aqui):**
- Sugest√£o: crie `docs/estrutura_repositorio.png` e referencie:
  - `![Estrutura do reposit√≥rio](docs/estrutura_repositorio.png)`

Estrutura (resumo):

```text
CLASSIFICANDO-PERFIL-DE-CONCILIA√á√ÉO/
‚îú‚îÄ Abordagem-com-LLM/
‚îÇ  ‚îú‚îÄ Dados/
‚îÇ  ‚îÇ  ‚îî‚îÄ dados_processos_cejusc_14052025.json
‚îÇ  ‚îú‚îÄ Conciliacao.ipynb
‚îÇ  ‚îú‚îÄ dados_processos_completo.csv
‚îÇ  ‚îî‚îÄ embeddings_cejusc.npy
‚îú‚îÄ An√°lise-Estat√≠stica-do-Corpus/
‚îÇ  ‚îî‚îÄ Statistical-Corpus-Analysis.ipynb
‚îú‚îÄ Conciliacao/
‚îÇ  ‚îú‚îÄ dados/
‚îÇ  ‚îÇ  ‚îú‚îÄ cejusc_03072025/
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ dados_processos_cejusc_03072025_V1.csv
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ dados_processos_cejusc_03072025_V2.csv
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ dados_processos_cejusc_03072025_V3.csv
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ dados_processos_cejusc_03072025.json
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ dados_processos_cejusc_03072025_V1_enriquecidos.json
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ frequencia_tokens_artificiais.txt
‚îÇ  ‚îÇ  ‚îî‚îÄ cejusc_14052025/
‚îÇ  ‚îÇ     ‚îú‚îÄ dados_processos_cejusc_14052025_V1.csv
‚îÇ  ‚îÇ     ‚îú‚îÄ dados_processos_cejusc_14052025_V2.csv
‚îÇ  ‚îÇ     ‚îú‚îÄ dados_processos_cejusc_14052025_V3.csv
‚îÇ  ‚îÇ     ‚îú‚îÄ dados_processos_cejusc_14052025.json
‚îÇ  ‚îÇ     ‚îú‚îÄ dados_processos_cejusc_14052025_V1_enriquecidos.json
‚îÇ  ‚îÇ     ‚îî‚îÄ frequencia_tokens_artificiais.txt
‚îÇ  ‚îî‚îÄ Embeddings/
‚îÇ     ‚îú‚îÄ checkpoint_parcial.npy
‚îÇ     ‚îú‚îÄ checkpoint_partial_03072025.npy
‚îÇ     ‚îú‚îÄ dados_processos_cejusc_14052025_rejeitados.json
‚îÇ     ‚îú‚îÄ dados_processos_cejusc_14052025_V1_enriquecidos_Embeddings.json
‚îÇ     ‚îú‚îÄ dados_processos_cejusc_14052025_V1_enriquecidos_Embeddings.npy
‚îÇ     ‚îî‚îÄ ...
‚îú‚îÄ Scripts/
‚îÇ  ‚îú‚îÄ gerar_embeddings_gemini.py
‚îÇ  ‚îú‚îÄ gerar_features_gemini.py
‚îÇ  ‚îú‚îÄ gerar_features_sentence_transformers.py
‚îÇ  ‚îú‚îÄ classificar_com_gemini.py
‚îÇ  ‚îú‚îÄ checkpoint_parcial.json
‚îÇ  ‚îî‚îÄ br-tjgo-cld-02-09b1b22e65b3.json
‚îú‚îÄ Notebooks/
‚îÇ  ‚îú‚îÄ XGBoost/
‚îÇ  ‚îÇ  ‚îú‚îÄ XGBoost.ipynb
‚îÇ  ‚îÇ  ‚îú‚îÄ XGBoost-V2.ipynb
‚îÇ  ‚îÇ  ‚îî‚îÄ modelo_classificacao_xgb.pkl
‚îÇ  ‚îú‚îÄ Random-Forest/
‚îÇ  ‚îÇ  ‚îú‚îÄ Random-Forest.ipynb
‚îÇ  ‚îÇ  ‚îî‚îÄ modelo_rf_classificacao.pkl
‚îÇ  ‚îú‚îÄ LightGBM/
‚îÇ  ‚îÇ  ‚îú‚îÄ LightGBM.ipynb
‚îÇ  ‚îÇ  ‚îî‚îÄ modelo_lightgbm_v1.pkl
‚îÇ  ‚îú‚îÄ CatBoost/
‚îÇ  ‚îÇ  ‚îú‚îÄ CatBoost.ipynb
‚îÇ  ‚îÇ  ‚îú‚îÄ CatBoost.pkl
‚îÇ  ‚îÇ  ‚îî‚îÄ catboost_info/ (logs/artefatos)
‚îÇ  ‚îú‚îÄ pre-processamento.ipynb
‚îÇ  ‚îî‚îÄ analisar_regex.ipynb
‚îî‚îÄ XGBoost-Producao-Teste/
   ‚îú‚îÄ App/
   ‚îÇ  ‚îú‚îÄ app.py
   ‚îÇ  ‚îú‚îÄ modelo_xgboost.pkl
   ‚îÇ  ‚îú‚îÄ modelo_randomforest.pkl
   ‚îÇ  ‚îú‚îÄ templates/index.html
   ‚îÇ  ‚îî‚îÄ static/Logo.png
   ‚îú‚îÄ Dados/
   ‚îÇ  ‚îú‚îÄ Embeddings/vetores_texto.npy
   ‚îÇ  ‚îú‚îÄ dados_processos_cejusc_limpos.json
   ‚îÇ  ‚îú‚îÄ dados_processos_cejusc_features.json
   ‚îÇ  ‚îî‚îÄ dados_processos_cejusc_14052025.csv
   ‚îú‚îÄ Notebooks/
   ‚îÇ  ‚îú‚îÄ pre-processamento-dados.ipynb
   ‚îÇ  ‚îî‚îÄ xgboost.ipynb
   ‚îú‚îÄ Dockerfile
   ‚îú‚îÄ docker-compose.yml
   ‚îî‚îÄ requirements.txt
```

---

## O que N√ÉO deve subir no GitHub (e por qu√™)

### 1) Dados brutos e derivados (LGPD / volume / reprodutibilidade)
‚ùå **N√£o versionar:**
- `**/Dados/**/*.csv`
- `**/Dados/**/*.json`
- `**/Conciliacao/dados/**`
- `**/frequencia_tokens_artificiais.txt` (se contiver tokens derivados de dados reais)

‚úÖ **Como lidar no GitHub:**
- Suba **apenas a estrutura** (pastas vazias com `.gitkeep`) e/ou **um exemplo anonimizado** (ex.: `sample_dados.csv`).

---

### 2) Embeddings e vetores (pesados + derivados)
‚ùå **N√£o versionar:**
- `**/*.npy`
- `**/*Embeddings*.json`
- `**/*Embeddings*.npy`
- `**/Embeddings/**`

Motivo: s√£o arquivos grandes, derivados do dado, e n√£o agregam rastreabilidade no Git (al√©m de custo de armazenamento).

---

### 3) Checkpoints e estados parciais (reentr√¢ncia)
‚ùå **N√£o versionar:**
- `checkpoint_parcial.json`
- `checkpoint_parcial.npy`
- `checkpoint_partial_*.npy`
- quaisquer arquivos ‚Äúcheckpoint‚Äù criados para retomar execu√ß√£o

Motivo: s√£o artefatos tempor√°rios, espec√≠ficos da m√°quina/execu√ß√£o.

---

### 4) Modelos treinados (PKL / bin√°rios)
‚ùå **N√£o versionar (recomendado):**
- `**/*.pkl`
- `**/*.joblib`

Motivo: bin√°rios podem ser grandes; podem mudar a cada treino; e √†s vezes s√£o sens√≠veis (podem ‚Äúmemorizar‚Äù padr√µes).  
‚úÖ Alternativas:
- publicar modelos em um **Model Registry** (ou na se√ß√£o de releases)
- versionar apenas o c√≥digo + pipeline de treino e ‚Äúcomo reproduzir‚Äù

> Exce√ß√£o: se for um reposit√≥rio did√°tico/pequeno e o modelo for leve e n√£o sens√≠vel, voc√™ *pode* subir, mas o ideal √© n√£o.

---

### 5) Logs de treino / lixo de execu√ß√£o
‚ùå **N√£o versionar:**
- `catboost_info/`
- `events.out.tfevents*`
- `tmp/`
- `*.tsv` gerado por treino
- `.ipynb_checkpoints/`
- `__pycache__/`, `*.pyc`

---

## Pastas que DEVEM existir (mesmo vazias)

Para facilitar a reprodu√ß√£o por terceiros, mantenha a estrutura e crie as pastas abaixo no clone:

```text
Conciliacao/dados/
Conciliacao/Embeddings/
XGBoost-Producao-Teste/Dados/
XGBoost-Producao-Teste/Dados/Embeddings/
docs/   (opcional, para prints)
```

Sugest√£o: crie um arquivo `.gitkeep` em cada pasta vazia.

---

## Sugest√£o de `.gitignore` (cobre dados, embeddings, checkpoints, modelos e logs)

> Se voc√™ j√° tem um `.gitignore`, compare com este e incorpore o que faltar.

```gitignore
# =========================
# DADOS (LGPD / n√£o versionar)
# =========================
**/Dados/**/*.csv
**/Dados/**/*.json
**/Conciliacao/dados/**
**/dados/**/*.csv
**/dados/**/*.json

# =========================
# EMBEDDINGS / VETORES
# =========================
**/*.npy
**/Embeddings/**
**/*Embeddings*.json
**/*Embeddings*.npy

# =========================
# CHECKPOINTS
# =========================
**/checkpoint*.json
**/checkpoint*.npy

# =========================
# MODELOS TREINADOS
# =========================
**/*.pkl
**/*.joblib

# =========================
# LOGS / ARTEFATOS DE TREINO
# =========================
**/catboost_info/
**/events.out.tfevents*
**/tmp/
**/*.tsv

# =========================
# JUPYTER / PYTHON
# =========================
.ipynb_checkpoints/
__pycache__/
*.pyc
.venv/
.env
```

---

## Como reproduzir 

1) **Coloque os dados localmente** nas pastas `Dados/` (ou em `Conciliacao/dados/cejusc_*/`).  
2) Rode scripts em `Scripts/` para:
   - gerar features (`gerar_features_*.py`)
   - gerar embeddings (`gerar_embeddings_*.py`)
3) Use os notebooks em `Notebooks/` para treinar/avaliar (XGBoost/RF/LGBM/CatBoost).
4) Se quiser servir, use `XGBoost-Producao-Teste/` (Docker + app).

---

Link dos dados usados no projeto: https://huggingface.co/datasets/Willgnner-Santos/Classificando-Perfil-de-Conciliacao

---


